{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import configparser\n",
    "from datetime import date\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import r2_score, accuracy_score, precision_score, recall_score, f1_score, precision_recall_curve\n",
    "from sklearn.feature_selection import chi2, f_regression, SelectKBest\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats import iqr\n",
    "from sklearn.preprocessing import scale, PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import yfinance as yf\n",
    "from sklearn.datasets import make_hastie_10_2\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=(FutureWarning))\n",
    "\n",
    "\n",
    "pd.set_option('use_inf_as_na',True)\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "comission = {}\n",
    "with open('/Users/p.matchenkov/Desktop/comissions.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        (key, val) = line.split(':')\n",
    "        comission[key] = float(str(val)[:-1])/100\n",
    "comission_df = pd.DataFrame(list(comission.items()), columns=['order_symbol', 'comission_rate'])\n",
    "\n",
    "\n",
    "def connect():\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('/Users/p.matchenkov/NotebookProjects/configurations/config.ini')\n",
    "    password = config['PASSWORDS']['password']\n",
    "    localhost = config['LOCALHOST']['localhost']\n",
    "    db_name = config['NAMES']['bd_name']\n",
    "    db_type = config['NAMES']['bd_type']\n",
    "    login = config['PASSWORDS']['login']\n",
    "\n",
    "    engine = create_engine(f'{db_type}://{login}:{password}@{localhost}/{db_name}')\n",
    "    try:\n",
    "        engine.connect()\n",
    "        #print('connections success')\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "    return engine\n",
    "\n",
    "def connect_to_cexlive():\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('/Users/p.matchenkov/NotebookProjects/configurations/config.ini')\n",
    "    password = config['PASSWORDS']['cexlive_password']\n",
    "    localhost = config['CEX_prod']['localhost']\n",
    "    db_name = config['CEX_prod']['bd_name']\n",
    "    db_type = config['CEX_prod']['bd_type']\n",
    "    login = config['CEX_prod']['login']\n",
    "\n",
    "    engine = create_engine(f'{db_type}://{login}:{password}@{localhost}/{db_name}')\n",
    "    conn = engine.connect()\n",
    "    try:\n",
    "        engine.connect()\n",
    "        #print('connections success')\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "    return engine\n",
    "\n",
    "def get_price_from_db(dates):\n",
    "    engine = connect()\n",
    "    request = f\"\"\"\n",
    "    select symbol, close, date_added \n",
    "    from market_data\n",
    "    where symbol in ('BTC/USD', 'EUR/USD', 'GBP/USD', 'ETH/USD') and date_added in {dates} and candle = 'h'\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(engine.execute(request)).drop_duplicates(subset=['symbol', 'date_added'])\\\n",
    "        .rename(columns={'symbol': 'order_symbol', 'date_added': 'executed_date'})\n",
    "    df['quote_currency'] = df['order_symbol'].str.extract('/(.*)')\n",
    "    req_jpy = f\"\"\"\n",
    "    select symbol, (1/`close`), date_added \n",
    "    from market_data\n",
    "    where symbol = 'USD/JPY' and date_added in {dates} and candle = 'h'\n",
    "    \"\"\"\n",
    "    jpy_df = pd.DataFrame(engine.execute(req_jpy)).drop_duplicates(subset=['symbol', 'date_added'])\\\n",
    "        .rename(columns={'divide(1, close)': 'close', 'symbol': 'order_symbol', 'date_added': 'executed_date'})\n",
    "    jpy_df['quote_currency'] = jpy_df['order_symbol'].str.extract('(.*)/')\n",
    "    df = pd.concat([df, jpy_df]).drop(columns='order_symbol')\n",
    "    return df\n",
    "\n",
    "def get_deposit(users):\n",
    "    engine = connect()\n",
    "    request = f\"\"\"\n",
    "    select * \n",
    "    from finance_statistics_hour \n",
    "    where record_type in ('deposit', 'withdrawal')\n",
    "    and symbol != 'EUR' \n",
    "    and user_id in {tuple(users)}\n",
    "    order by date_time_added\n",
    "    \"\"\"\n",
    "    deps = pd.DataFrame(engine.execute(request)).drop_duplicates()[['user_id', 'account_id', 'symbol', 'record_type', 'total_amount', 'date_added']]\\\n",
    "        .rename(columns={'date_added': 'executed_date', 'symbol': 'quote_currency'})\n",
    "    deps = deps.merge(get_price_from_db(tuple(deps['executed_date'].astype(str).unique())),\n",
    "                      how='left', on=['executed_date', 'quote_currency'])\\\n",
    "                      .fillna(1)\n",
    "    deps['deposit'] = deps['total_amount'].loc[deps['record_type'] == 'deposit'] * deps['close']\n",
    "    deps['withdrawal'] = deps['total_amount'].loc[deps['record_type'] == 'withdrawal'] * deps['close']\n",
    "    deps['date'] = pd.to_datetime(deps['executed_date']) #- pd.to_timedelta(7, unit='d')\n",
    "    deps = deps.groupby('user_id').agg({'deposit': ['sum', 'mean'], 'withdrawal': ['sum', 'mean']}).reset_index()\n",
    "    deps.columns = ['user_id', 'deposit', 'mean_deposit', 'withdrawal', 'mean_withdrawal']\n",
    "    return deps\n",
    "\n",
    "def avg_trade_time(orders):\n",
    "    df = orders[['user_id', 'account_id', 'executed_date_time', 'position_code']].loc[orders['position_effect'] == 'OPENING']\\\n",
    "        .merge(orders[['executed_date_time', 'position_code']].loc[orders['position_effect'] == 'CLOSING'], how='left', on = 'position_code')\n",
    "    \n",
    "    df['time_open'] = pd.to_datetime(df['executed_date_time_x']) #- pd.to_timedelta(7, unit='d')\n",
    "    df['time_close'] = pd.to_datetime(df['executed_date_time_y']) #- pd.to_timedelta(7, unit='d')\n",
    "\n",
    "    df['trade_time'] = (df['time_close'] - df['time_open'])#.total_seconds()\n",
    "    df['trade_time'] = df['trade_time'] / np.timedelta64(1, 'h')\n",
    "    df = df.drop(columns={'executed_date_time_x', 'position_code', 'executed_date_time_y'})\n",
    "    \n",
    "    df = df.groupby('user_id').agg({'trade_time': 'mean'}).reset_index()\\\n",
    "        .rename(columns={'time_close': 'date'})\n",
    "    return df\n",
    "\n",
    "def get_account_leverage(accounts):\n",
    "    req = f\"\"\"\n",
    "    select name, a.account_code from account_groups ag \n",
    "    join account_to_groups atg on ag.id = atg.group_id join accounts a on a.id = atg.account_id \n",
    "    where name like ('Leverage%%') and a.clearing_code = 'live'\n",
    "    and a.account_code in {tuple(accounts)}\n",
    "    \"\"\"\n",
    "    engine = connect_to_cexlive()\n",
    "    df = pd.DataFrame(engine.execute(req)).drop_duplicates().rename(columns={'account_code': 'account_id'})\n",
    "    return df\n",
    "\n",
    "def get_lag_btw_dep_trade(users):\n",
    "    req = f\"\"\"\n",
    "    select min(executed_date_time), user_id, account_created_date_time \n",
    "    from order_statistics os\n",
    "    where user_id in {tuple(users)}\n",
    "    group by user_id, account_created_date_time\n",
    "    \"\"\"\n",
    "    engine = connect()\n",
    "    df = pd.DataFrame(engine.execute(req))\n",
    "    df.columns = ['executed_date_time', 'user_id', 'created_date_time']\n",
    "    df = df.sort_values('executed_date_time', ascending=True).drop_duplicates('user_id')\n",
    "    df['first_time_trade'] = (df['executed_date_time'] - df['created_date_time']).dt.days\n",
    "    df = df.drop(columns={'executed_date_time', 'created_date_time'})\n",
    "    return df\n",
    "\n",
    "def get_first_deposit(users):\n",
    "    engine = connect()\n",
    "    request = f\"\"\"\n",
    "    select  min(date_added) as executed_date , user_id, symbol as quote_currency, total_amount\n",
    "        from finance_statistics_hour \n",
    "        where record_type = 'deposit' and user_id in {tuple(users)}\n",
    "    GROUP by  user_id, symbol, total_amount\n",
    "        order by executed_date\n",
    "    \"\"\"\n",
    "    first_deps = pd.DataFrame(engine.execute(request)).drop_duplicates('user_id')[['user_id','quote_currency', 'total_amount', 'executed_date']]\n",
    "        \n",
    "    dates = tuple(first_deps['executed_date'].astype(str).unique())\n",
    "    first_deps = first_deps.merge(get_price_from_db(dates), how='left', on=['executed_date', 'quote_currency'])\n",
    "    first_deps.loc[first_deps['quote_currency']=='USDT', 'close'] = first_deps['close'].loc[first_deps['quote_currency']=='USDT'].fillna(1)\n",
    "    first_deps['first_dep_usd'] = first_deps['total_amount'] * first_deps['close']\n",
    "    return first_deps[['user_id', 'first_dep_usd']]\n",
    "\n",
    "def get_btc_price(dates):\n",
    "    engine = connect()\n",
    "    request = f\"\"\"\n",
    "    select symbol, close as btc, date_added as created_date\n",
    "    from market_data\n",
    "    where symbol in ('BTC/USD') and date_added in {tuple(dates)} and candle = 'd'\n",
    "    group by symbol, btc, created_date\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(engine.execute(request)).drop_duplicates(subset=['created_date'])\n",
    "    df['created_date'] = df['created_date'].astype(str)\n",
    "    df['symbol'] = df['symbol'].str.extract('/(.*)')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    return accuracy_score(y_true, y_pred)\n",
    "\n",
    "def precision(y_true: np.ndarray, y_pred: np.ndarray) -> np.float64:\n",
    "    return precision_score(y_true, y_pred)\n",
    "\n",
    "def recall(y_true: np.ndarray, y_pred: np.ndarray) -> np.float64:\n",
    "    return recall_score(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_train: np.ndarray,\n",
    "                y_train_pred: np.ndarray,\n",
    "            \n",
    "                y_test: np.ndarray,\n",
    "                y_pred: np.ndarray,\n",
    "                name: str,\n",
    "                model,\n",
    "                x: np.ndarray,\n",
    "                y: np.ndarray,\n",
    "                ):  \n",
    "    \"\"\"Генерация таблицы с метриками\"\"\"\n",
    "    df_metrics = pd.DataFrame()\n",
    "\n",
    "    df_metrics['model'] = [name]\n",
    "\n",
    "    df_metrics['train_accuracy'] = accuracy_score(y_train, y_train_pred)\n",
    "    df_metrics['test_accuracy'] = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    df_metrics['recall'] = recall_score(y_test, y_pred)\n",
    "    df_metrics['precision'] = precision_score(y_test, y_pred)\n",
    "\n",
    "    df_metrics['F1'] = f1_score(y_test, y_pred)\n",
    "\n",
    "    df_metrics['cv_roc_auc'] = cross_val_score(model, x, y, cv=5, scoring='roc_auc').mean() #verbose=2\n",
    "    df_metrics['pr_auc'] = cross_val_score(model, x, y, cv=5, scoring='average_precision').mean() # verbose=2\n",
    "\n",
    "    return df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = ['AAPL', 'AMZN', 'META', 'TSLA', 'SPC', 'NFLX', 'TWTR', 'GOOG']\n",
    "forex = ['USD/JPY', 'EUR/GBP', 'USD/RUB', 'EUR/JPY', 'EUR/USD', 'GBP/JPY', 'GBP/USD', 'XAG/USD', 'XAU/USD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_from = '2020-01-01' #'2022-09-01'\n",
    "date_to = date.today() #+ pd.to_timedelta(1, unit='d')\n",
    "source = 'file'\n",
    "\n",
    "if source == 'db':\n",
    "    req = f\"\"\"\n",
    "    select * from order_statistics where executed_date_time between '{date_from}' and '{date_to}'\n",
    "    and account_clearing_code = 'live'\n",
    "    order by executed_date_time\"\"\"\n",
    "\n",
    "    engine = connect()\n",
    "    orders = pd.DataFrame(engine.execute(req)).drop_duplicates()\\\n",
    "        [['account_id', 'order_strategy', 'order_symbol', 'price', 'quantity', 'quote_currency',\n",
    "        'executed_date', 'executed_date_time', 'order_pl', 'position_code', 'position_effect', 'order_id', 'user_created_date_time']]\\\n",
    "                                                                .replace('USDT', 'USD')\\\n",
    "                                                               .replace('', np.nan).fillna({'quote_currency': 'USD'})\n",
    "elif source == 'file':\n",
    "    orders = pd.read_csv(r\"/Users/p.matchenkov/NotebookProjects/users/data/input/all_history.csv\", low_memory=False)\\\n",
    "        [['user_id', 'account_id', 'order_strategy', 'order_symbol', 'price', 'quantity', 'quote_currency', 'executed_date', \n",
    "        'executed_date_time', 'order_pl', 'position_code', 'position_effect', 'order_id', 'user_created_date_time']]\\\n",
    "                                                                .replace('USDT', 'USD')\\\n",
    "                                                               .replace('', np.nan).fillna({'quote_currency': 'USD'}).drop_duplicates()                                                             \n",
    "\n",
    "orders = orders.loc[~orders['order_symbol'].isin(forex+stocks)]                                                       \n",
    "orders['date'] = pd.to_datetime(orders['executed_date']) #- pd.to_timedelta(1, unit='d')\n",
    "dates = tuple(orders['executed_date'].astype(str).unique())\n",
    "\n",
    "quote_currencies_prices = get_price_from_db(dates)\n",
    "\n",
    "orders = orders.merge(quote_currencies_prices, how='left', on=['executed_date', 'quote_currency'])\\\n",
    "              .replace('', np.nan).fillna(1)\n",
    "orders['pnl'] = orders['order_pl'] * orders['close']\n",
    "orders['volume'] = orders['price'] * orders['quantity'] * orders['close']\n",
    "orders = orders.merge(comission_df, how='left', on='order_symbol')\n",
    "orders['comission'] = orders['volume'] * orders['comission_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = orders.copy()\n",
    "\n",
    "\n",
    "# getting leverages df to add to result \n",
    "accounts = result['account_id'].unique()\n",
    "levereges = get_account_leverage(accounts=accounts)\n",
    "levereges = levereges.merge(orders.groupby('account_id').agg({'comission': 'count'}), how='left', on='account_id')\n",
    "levereges['leverage'] = levereges['name'].str.extract('\\:(.*)')\n",
    "levereges['leverage'] = levereges['leverage'].astype(float) * levereges['comission'].astype(float)\n",
    "levereges['user_id'] = levereges['account_id'].str.extract('_(.*)_')\n",
    "\n",
    "\n",
    "# sum features by week\n",
    "result = result.groupby('user_id')\\\n",
    "    .agg({'pnl': sum, 'comission': 'sum', 'volume': ['sum', 'mean', 'median'],\n",
    "        'order_pl': 'count', 'account_id': pd.Series.nunique, 'user_created_date_time': 'first'})\\\n",
    "    .reset_index()\n",
    "result.columns = ['user_id', 'pnl', 'comission', 'volume_sum', 'volume_mean', 'volume_median', 'trades_qty', 'accounts_count', 'created_date']\n",
    "result['created_date'] = pd.to_datetime(result['created_date']).dt.date#.astype(str)\n",
    "result['account_age'] = (date.today() -  result['created_date']).dt.days\n",
    "result['created_date'] = result['created_date'].astype(str)\n",
    "\n",
    "\n",
    "# adding deposits\n",
    "users_id = result['user_id'].unique()\n",
    "result = result.merge(get_deposit(users_id), how='left', on='user_id')\n",
    "result['deposit'] = result['deposit'].fillna(result['deposit'].median())\n",
    "result['withdrawal'] = result['withdrawal'].fillna(result['withdrawal'].median())\n",
    "\n",
    "\n",
    "# creating df with avg trade time\n",
    "result = result.merge(avg_trade_time(orders), how='left', on='user_id')\n",
    "result['trade_time'] = result['trade_time'].fillna(result['trade_time'].median())\n",
    "\n",
    "\n",
    "# create df with counts of accs levereges and addint to result dataframe\n",
    "levereges = levereges.groupby('user_id').agg({'leverage': 'sum'}).reset_index()\n",
    "\n",
    "\n",
    "# adding first deposit amount in usd\n",
    "result = result.merge(get_first_deposit(result['user_id']) , how='left', on='user_id')\n",
    "result['first_dep_usd'] = result['first_dep_usd'].fillna(result['first_dep_usd'].median())\n",
    "\n",
    "\n",
    "# add btc for created account_date\n",
    "btc_price = yf.Ticker('BTC-USD')\n",
    "btc_hist = btc_price.history(period=\"42mo\").reset_index().drop_duplicates()\n",
    "btc_hist['created_date'] = btc_hist['Date'].dt.date.astype(str)\n",
    "btc_hist = btc_hist[['created_date', 'Close']]\n",
    "result = result.merge(btc_hist, how='left', on='created_date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id              0\n",
       "pnl                  0\n",
       "comission            0\n",
       "volume_sum           0\n",
       "volume_mean          0\n",
       "volume_median        0\n",
       "trades_qty           0\n",
       "accounts_count       0\n",
       "created_date         0\n",
       "account_age          0\n",
       "deposit              0\n",
       "mean_deposit         0\n",
       "withdrawal           0\n",
       "mean_withdrawal      0\n",
       "trade_time           0\n",
       "first_dep_usd        0\n",
       "Close              501\n",
       "dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['mean_deposit'] = result['mean_deposit'].fillna(result['mean_deposit'].median())\n",
    "result['mean_withdrawal'] = result['mean_withdrawal'].fillna(result['mean_withdrawal'].median())\n",
    "result.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.loc[result['created_date'] < '2019-03-01', 'Close'] = result['Close'].fillna(3700)\n",
    "result.loc[(result['created_date'] >= '2019-03-01') & (result['created_date'] < '2019-06-01'), 'Close'] = result['Close'].fillna(4200)\n",
    "result.loc[(result['created_date'] >= '2019-06-01') & (result['created_date'] < '2019-12-31'), 'Close'] = result['Close'].fillna(7000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['dep-withd'] = result['deposit'] - result['withdrawal']\n",
    "result['dep+withd'] = result['deposit'] + result['withdrawal']\n",
    "result['dep*withd'] = result['deposit'] * result['withdrawal']\n",
    "result['dep/withd'] = result['deposit'] / result['withdrawal']\n",
    "result['trades/accounts'] = result['trades_qty'] / result['accounts_count']\n",
    "result['deposit/volume_sum'] = result['deposit'] / result['volume_sum']\n",
    "result['deposit/trades_qty'] = result['deposit'] / result['trades_qty']\n",
    "result['dep/btc'] = result['deposit'] / result['Close']\n",
    "\n",
    "result['dep/withd'] = result['dep/withd'].fillna(0)\n",
    "\n",
    "#result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding target\n",
    "result.loc[result['pnl']>=0, 'pnl'] = 0\n",
    "result.loc[result['pnl']<0, 'pnl'] = 1\n",
    "#result.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3154, 25)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = 42\n",
    "\n",
    "x = result.drop(columns={'pnl', 'user_id', 'created_date'})\n",
    "y = result['pnl']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=random, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8205453392517438"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result.loc[result['pnl'] == 1]) / len(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logical regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>F1</th>\n",
       "      <th>cv_roc_auc</th>\n",
       "      <th>pr_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  train_accuracy  test_accuracy  recall  precision   F1  \\\n",
       "0  LogisticRegression            0.83           0.81    0.99       0.82 0.90   \n",
       "\n",
       "   cv_roc_auc  pr_auc  \n",
       "0        0.62    0.88  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "     'penalty': ['l1', 'l2'],\n",
    "     'solver': ['liblinear', 'saga']  \n",
    " }\n",
    "\n",
    "log_reg = GridSearchCV(LogisticRegression(random_state=random, max_iter=10000), param_grid=params, cv=5)\n",
    "log_reg.fit(x_train, y_train)\n",
    "\n",
    "y_train_pred = log_reg.predict(x_train)\n",
    "y_test_pred = log_reg.predict(x_test)\n",
    "\n",
    "metrics_df = get_metrics(y_train,\n",
    "                          y_train_pred,\n",
    "                          y_test,\n",
    "                          y_test_pred,\n",
    "                          'LogisticRegression',\n",
    "                          log_reg,\n",
    "                          x,\n",
    "                          y)\n",
    "metrics_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desicion Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>F1</th>\n",
       "      <th>cv_roc_auc</th>\n",
       "      <th>pr_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  train_accuracy  test_accuracy  recall  precision  \\\n",
       "0      LogisticRegression            0.83           0.81    0.99       0.82   \n",
       "0  DecisionTreeClassifier            0.86           0.82    0.97       0.83   \n",
       "\n",
       "    F1  cv_roc_auc  pr_auc  \n",
       "0 0.90        0.62    0.88  \n",
       "0 0.90        0.75    0.91  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth': np.arange(2, 100, 2),\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "dec_tree = GridSearchCV(DecisionTreeClassifier(random_state=random), param_grid=params, cv=5)\n",
    "dec_tree.fit(x_train, y_train)\n",
    "\n",
    "y_train_pred = dec_tree.predict(x_train)\n",
    "y_test_pred = dec_tree.predict(x_test)\n",
    "\n",
    "metrics_df = metrics_df.append(get_metrics(y_train,\n",
    "                                           y_train_pred,\n",
    "                                           y_test,\n",
    "                                           y_test_pred,\n",
    "                                           'DecisionTreeClassifier',\n",
    "                                           model=dec_tree,\n",
    "                                           x=x,\n",
    "                                           y=y\n",
    "                                           ))\n",
    "metrics_df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>F1</th>\n",
       "      <th>cv_roc_auc</th>\n",
       "      <th>pr_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model  train_accuracy  test_accuracy  recall  \\\n",
       "0          LogisticRegression            0.83           0.81    0.99   \n",
       "0      DecisionTreeClassifier            0.86           0.82    0.97   \n",
       "0  GradientBoostingClassifier            0.90           0.86    0.98   \n",
       "\n",
       "   precision   F1  cv_roc_auc  pr_auc  \n",
       "0       0.82 0.90        0.62    0.88  \n",
       "0       0.83 0.90        0.75    0.91  \n",
       "0       0.87 0.92        0.81    0.94  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "     'criterion': ['friedman_mse', 'squared_error'], \n",
    "     'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "#      'learning_rate': np.arange(0.1 , 1.1, 0.1),      'min_weight_fraction_leaf': np.arange(0.0, 0.5, 0.1),\n",
    "grad_boost_class = GridSearchCV(GradientBoostingClassifier(random_state=random), param_grid=params, cv=5)\n",
    "grad_boost_class.fit(x_train, y_train)\n",
    "\n",
    "y_train_pred = grad_boost_class.predict(x_train)\n",
    "y_test_pred = grad_boost_class.predict(x_test)\n",
    "\n",
    "metrics_df = metrics_df.append(get_metrics(y_train,\n",
    "                                           y_train_pred,\n",
    "                                           y_test,\n",
    "                                           y_test_pred,\n",
    "                                           'GradientBoostingClassifier',\n",
    "                                           grad_boost_class,\n",
    "                                           x,\n",
    "                                           y))\n",
    "metrics_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>F1</th>\n",
       "      <th>cv_roc_auc</th>\n",
       "      <th>pr_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model  train_accuracy  test_accuracy  recall  \\\n",
       "0          LogisticRegression            0.83           0.81    0.99   \n",
       "0      DecisionTreeClassifier            0.86           0.82    0.97   \n",
       "0  GradientBoostingClassifier            0.90           0.86    0.98   \n",
       "0      RandomForestClassifier            1.00           0.87    0.97   \n",
       "\n",
       "   precision   F1  cv_roc_auc  pr_auc  \n",
       "0       0.82 0.90        0.62    0.88  \n",
       "0       0.83 0.90        0.75    0.91  \n",
       "0       0.87 0.92        0.81    0.94  \n",
       "0       0.88 0.93        0.83    0.94  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'max_features': ['sqrt', 'log2', None] \n",
    "} \n",
    "\n",
    "rand_forest = GridSearchCV(RandomForestClassifier(random_state=random), param_grid=params)\n",
    "rand_forest.fit(x_train, y_train)\n",
    "\n",
    "y_train_pred = rand_forest.predict(x_train)\n",
    "y_test_pred = rand_forest.predict(x_test)\n",
    "\n",
    "metrics_df = metrics_df.append(get_metrics(y_train,\n",
    "                                           y_train_pred,\n",
    "                                           y_test,\n",
    "                                           y_test_pred,\n",
    "                                           'RandomForestClassifier',\n",
    "                                           rand_forest,\n",
    "                                           x,\n",
    "                                           y))\n",
    "metrics_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>F1</th>\n",
       "      <th>cv_roc_auc</th>\n",
       "      <th>pr_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model  train_accuracy  test_accuracy  recall  \\\n",
       "0          LogisticRegression            0.83           0.81    0.99   \n",
       "0      DecisionTreeClassifier            0.86           0.82    0.97   \n",
       "0  GradientBoostingClassifier            0.90           0.86    0.98   \n",
       "0      RandomForestClassifier            1.00           0.87    0.97   \n",
       "0                         SVM            0.83           0.81    1.00   \n",
       "\n",
       "   precision   F1  cv_roc_auc  pr_auc  \n",
       "0       0.82 0.90        0.62    0.88  \n",
       "0       0.83 0.90        0.75    0.91  \n",
       "0       0.87 0.92        0.81    0.94  \n",
       "0       0.88 0.93        0.83    0.94  \n",
       "0       0.81 0.90        0.67    0.90  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(probability=True, random_state=random, kernel='rbf')\n",
    "svc.fit(x_train, y_train)\n",
    "\n",
    "y_train_pred = svc.predict(x_train)\n",
    "y_test_pred = svc.predict(x_test)\n",
    "\n",
    "metrics_df = metrics_df.append(get_metrics(y_train,\n",
    "                                           y_train_pred,\n",
    "                                           y_test,\n",
    "                                           y_test_pred,\n",
    "                                           'SVM',\n",
    "                                           svc,\n",
    "                                           x,\n",
    "                                           y))\n",
    "metrics_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
